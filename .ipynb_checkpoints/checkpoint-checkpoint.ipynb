{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import fastai\n",
    "import fastai.vision\n",
    "import time, copy\n",
    "from pathlib import Path\n",
    "import core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Splicing\n",
    "\n",
    "Transfer learning has seen much success in the field of computer vision and more recently natural language processing. Specific approaches vary considerably, here we focus on extending a commonly used technique in which some of the weights and biases of a pre-trained model are loaded into a new architecture which is repurposed to some new tasks. This method has long since seen success in computer vision tasks and more recently in the field of natural language processing, popularized by Jeremy Howard and Sebastian Ruder in their paper introducing [ULMFiT ](https://arxiv.org/abs/1801.06146) and in Jeremy's [courses at fast.ai](https://course.fast.ai/) and later extended upon by folks at [google](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html) (adding bidirectionality) and [open.ai](https://blog.openai.com/language-unsupervised/) (replacing LSTM core with a transformer), altogether resulting in many state-of-the-art NLP results.\n",
    "\n",
    "Broadly speaking, this approach can be thought of as viewing a pretrained model as being composed of two pieces: a general-purpose *body* or *core* and a task-specific *head*. Thus far, applications of this approach involve replacing an existing *head* with a new one tailored for a specific task. Typically, in CV/NLP the core consists of the convolutional/recurrent components respectively, whereas the head is consist of pooling/flattening layers followed by a shallow multi-layer perceptron.\n",
    "\n",
    "Here we investigate the question: why is in each of these cases the new component is added only **on top of** existing components? Can anything be gained by **splicing new components directly into the core architecture**?\n",
    "\n",
    "Let us illustrate witha concrete example: suppose we has trained the following MLP for some regression task:\n",
    "\n",
    "`\n",
    "m = (nn.Sequential(nn.Linear(2,5), \n",
    "                   nn.ReLU(), \n",
    "                   nn.Linear(5,9), \n",
    "                   nn.ReLU(), \n",
    "                   nn.Linear(9,1)))\n",
    "`\n",
    "\n",
    "and one would like to add a layer *between* the first and second linear layer:\n",
    "\n",
    "`\n",
    "m_splice = (nn.Sequential(nn.Linear(2,5), \n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(5,5),      #Additional, un-trained component\n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(5,9), \n",
    "                          nn.ReLU(), \n",
    "                          nn.Linear(9,1)))\n",
    "`\n",
    "\n",
    "Some observations: if the weights of the newly introduced layer are initialized randomly, then we can be certain that model performance will collapse. Since the original layers were trained together, layer two (nn.Linear(5,9)) *expects* inputs to look a certain way, (e.g look like something layer one would have output). Essentially this degradation would be the result of an extreme case of covariate shift which would defeat the purpose of using the pre-trained weights.\n",
    "\n",
    "On the other hand, if we initialize the bias to zero and the weights to identity matrix, then the new layer has *no effect* on the model initially. Then if we freeze the learning rate on all the original layers, we can think of learning the weights of our new component as learning a post-processing of layer one output to be more 'palatable' for the rest of the network to consume in a similar spirit as batch-norm is introduced to post-process the output of layers to have desirable sample statistics. In practice, we anneal the learning rate on the layers surrounding the splice gradually from zero to some stable level while annealing the learning rate on the spliced component along a one cycle schedule as introduced [here](https://arxiv.org/abs/1708.07120). By monitoring gradient norms through the added component(s) as well as the original layers, one can propose a metric for determining the extent to which the architecture has 'accepted' or 'rejected' the new components. \n",
    "\n",
    "In this repo, we focus for now on convolutional and linear splicing and postpone experiments with splicing into recurrent architectures to a later date. Specifically, we are interested in exploring the following questions:\n",
    "\n",
    "1) If we begin by training an architecture (A1) to some stop criterion (where reduction in loss is minimal, over overfitting begins to occur, etc.) and then splice in components to achieve architecture (A2), are we able to train (A2) further to achieve an overall lower loss (or else better performance by some specified metric)? \n",
    "\n",
    "2) Consider fully trained architecture (A2) above, along with full training history (pre- and post- splice, beginning from scratch). Make a copy of the architecture denoted (B2) and re-initialize weights randomly and train (B2) from scratch. We are interested:\n",
    "* Does (B2) achieve worse, the same, or better *ultimate* performance (with a pre-defined stopping criterion specified a priori) as compared to (A2)\n",
    "* How does the complete training history of (A2*) compare to that of (A2)? \n",
    "        \n",
    "       \n",
    "An affirmative response to question (1) suggests a cheap, fast procedure for incrementally increasing a trained model's performance if slight increase in performance is necessary for an application. \n",
    "\n",
    "A positive response to question (2) suggests alternative paradigms for training deep neural networks, rather than initializing a very deep network completely at random, perhaps it is faster, more efficient, or ultimately result in a better performance if one begins with a shallower network and gradually adds depth, splicing in layers over time and training them gradually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading  data\n",
    "\n",
    "We make use of fastai easy-to-use data block API for loading one of several common datasets to test our approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Loading the MNIST dataset...\n",
    "url = fastai.datasets.URLs.MNIST\n",
    "path = fastai.datasets.untar_data(url)\n",
    "data = fastai.vision.ImageDataBunch.from_folder(path, train='training', valid='testing')\n",
    "learn = fastai.vision.create_cnn(data, models.resnet18, metrics=accuracy)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Loading the CIFAR dataset...\n",
    "url = fastai.datasets.URLs.CIFAR\n",
    "path = fastai.datasets.untar_data(url)\n",
    "data = (fastai.vision.ImageItemList.from_folder(path)\n",
    "        .split_by_folder(train='train', valid='test')\n",
    "        .label_from_folder()\n",
    "        .transform(fastai.vision.get_transforms(), size=224)\n",
    "        .databunch(bs=64))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  Loading the PETS dataset ... \n",
    "func = lambda x: str(x)[46:].rstrip('.jpg1234567890').rstrip('_')\n",
    "url = fastai.datasets.URLs.PETS\n",
    "path = fastai.datasets.untar_data(url)\n",
    "data = (fastai.vision.ImageItemList.from_folder(path/'images')\n",
    "        .random_split_by_pct()\n",
    "        .label_from_func(func)\n",
    "        .transform(fastai.vision.get_transforms(), size=224)\n",
    "        .databunch(bs=64))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"To load the FOOD dataset...\"\"\"\n",
    "path = Path('/home/max/Desktop/datasets/food-101/images')\n",
    "data = (fastai.vision.ImageItemList.from_folder(path)\n",
    "        .random_split_by_pct()\n",
    "        .label_from_folder()\n",
    "        .transform(fastai.vision.get_transforms(), size=112)\n",
    "        .databunch(bs=64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda x: str(x)[46:].rstrip('.jpg1234567890').rstrip('_')\n",
    "url = fastai.datasets.URLs.PETS\n",
    "path = fastai.datasets.untar_data(url)\n",
    "data = (fastai.vision.ImageItemList.from_folder(path/'images')\n",
    "        .random_split_by_pct()\n",
    "        .label_from_func(func)\n",
    "        .transform(fastai.vision.get_transforms(), size=112)\n",
    "        .databunch(bs=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastai benchmark\n",
    "\n",
    "While we're here might as well check out how fast.ai does on this task just to see how we're going along. You'll  notice how easy to use their API is (if you haven't checked it out yet, I highly recommend taking a look!)  Notice also we don't keep the pre-trained resnet weights for now since we're training our model from scratch too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = fastai.basic_train.Learner(data, model=core.cnn(nc=data.c), loss_func=nn.CrossEntropyLoss(), metrics=fastai.metrics.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xt4XPV95/H3dzQaXa2bJV+wwcLGXAIEMOaWC4HcNrBpCLnskjYLJd1Q0jTdtpvupptnSbdtml63JWELoTQ0bEPSBUoLaUIgtASScLONMQ43X7CNLNm6WBpZl9FoZr77xxyNhSLbY6wzc0b6vJ5nHs2cc2bO96eR5jO/c/kdc3dEREQAYuUuQEREokOhICIiBQoFEREpUCiIiEiBQkFERAoUCiIiUqBQEBGRAoWCiIgUKBRERKQgXu4CjlV7e7t3dnaWuwwRkYqycePGfnfvONpyFRcKnZ2dbNiwodxliIhUFDPbXcxy2nwkIiIFCgURESlQKIiISIFCQUREChQKIiJSoFAQEZEChYKIiBQoFEREKsDNP9zGE9v6Ql+PQkFEJOJyOefmR1/l6Z0HQl+XQkFEJOIOpjLkHFrqq0Nfl0JBRCTiBsfSALTWJ0Jfl0JBRCTiCqHQoJ6CiMiCNzQ2CUCLegoiIqLNRyIiUjAY9BRataNZRESGxtLEDJpqFQoiIgve4Fia5rpqYjELfV0KBRGRiBscmyzJ/gRQKIiIRN7QWLokJ66BQkFEJPIGR9VTEBGRQL6noFAQERGm9ilo85GIyIKXmswyPpmltUE9BRGRBe/QEBfqKYiILHilHOICFAoiIpE2FQrqKYiISGHzkXoKIiKizUciInKIdjSLiEjB4GiauuoqaqurSrK+0ELBzE4zs83TbsNm9pszljEz+6qZbTezLWa2Lqx6REQqUSlPXAOIh/XC7v4KcC6AmVUBe4H7Zyx2BbA2uF0E3Br8FBERSjvEBZRu89F7gB3uvnvG9KuAuzzvKaDFzJaXqCYRkcgbHEvT2lC6nkKpQuEa4NuzTF8BvD7tcVcwTUREyO9onlc9BTNLAB8C7plt9izTfJbXuMHMNpjZhr6+vrkuUUQksgbH0iXdp1CKnsIVwCZ33z/LvC7gxGmPVwLdMxdy99vdfb27r+/o6AipTBGRaMnlnOR46a6lAKUJhU8w+6YjgAeAa4OjkC4Gku7eU4KaREQibzg1Sc4p6eaj0I4+AjCzeuB9wK9Om3YjgLvfBnwPuBLYDowB14dZj4hIJRksDHExDw5JBXD3MWDxjGm3TbvvwGfDrEFEpFINlXiIC9AZzSIikVXqIS5AoSAiElmlHgwPFAoiIpE1WOJhs0GhICISWUNjaWIGi2pD3f37BgoFEZGIGgzGPYrFZjvPNxwKBRGRiBocmyzpTmZQKIiIRNbQWLqk+xNAoSAiElmDo6W9lgIoFEREIqvU11IAhYKISGSV+qproFAQEYmk1GSW8cmsegoiInJoiAvtaBYRkcIQFzokVUREFAoiInKINh+JiEhBOUZIBYWCiEgkleNaCqBQEBGJpMHRNHXVVdRWV5V0vQoFEZEIKseJa6BQEBGJpHIMcQEKBRGRSBocS9PaoJ6CiIiQ39GsnoKIiABBT0H7FEREJJdzkuOTJT9HARQKIiKRM5yaJOdo85GIiMDAaP5s5jbtaBYRkX3JFADLmupKvm6FgohIxPQEoXBCS23J1x1qKJhZi5nda2Yvm9lLZnbJjPmXmVnSzDYHt5vCrEdEpBL0DI0DsLSp9KEQD/n1bwYecvePmVkCqJ9lmSfc/YMh1yEiUjG6kykWNyRKPu4RhBgKZtYEXAr8MoC7p4F0WOsTEZkvepLjLC/DpiMId/PRaqAPuNPMnjOzO8ysYZblLjGz583s+2Z2Zoj1iIhUhH3JFMubS7+TGcINhTiwDrjV3c8DRoEvzFhmE7DK3c8Bvgb802wvZGY3mNkGM9vQ19cXYskiIuXXPTTO8ub511PoArrc/eng8b3kQ6LA3YfdfSS4/z2g2szaZ76Qu9/u7uvdfX1HR0eIJYuIlNfoRIbhVGb+9RTcfR/wupmdFkx6D/Di9GXMbJmZWXD/wqCegbBqEhGJup5k/sijchyOCuEfffQ54FvBkUc7gevN7EYAd78N+BjwGTPLAOPANe7uIdckIhJZU+colKunEGoouPtmYP2MybdNm38LcEuYNYiIVJKeoalQmH/7FERE5Bh1J8cxK8+Ja6BQEBGJlJ6hFO2NNSTi5fl4ViiIiERIz3CKE8q06QgUCiIikdIzNM4yhYKIiED+6KNyHXkECgURkcgYTk0yMpEp2zkKoFAQEYmMfWU+RwEUCiIikdEdXEehXOcogEJBRCQyCmczt6inICKy4PUMjRMzWLqopmw1KBRERCKiJ5liyaJa4lXl+2hWKIiIRERPMlXWcxRAoSAiEhndyfGyHo4KCgURkUhwd3qGynviGigUREQiYXg8w/hktqyHo4JCQUQkEroLV1xTT0FEZMGbugyndjSLiAjdwRXXTtA+BRER2ZdMEY8ZHWU8cQ0UCiIikdCdHGdpUy1VMStrHQoFEZEI6Bkq/4lroFAQEYmEnuR42Q9HhSJDwczWmFlNcP8yM/sNM2sJtzQRkYXB3elJpsp+OCoU31O4D8ia2SnA3wInA3eHVpWIyAIyODbJRCZXOT0FIOfuGeBq4K/c/beA5eGVJSKycETh4jpTig2FSTP7BHAd8N1gWnU4JYmILCw9EbgM55RiQ+F64BLgy+7+mpmdDPx9eGWJiCwc+4KzmZeXeYRUgHgxC7n7i8BvAJhZK7DI3f84zMJERBaK7mSK6iqjvaG8J65B8UcfPWZmTWbWBjwP3Glm/zvc0kREFoaeofyJa7Eyn7gGxW8+anb3YeAjwJ3ufj7w3qM9ycxazOxeM3vZzF4ys0tmzDcz+6qZbTezLWa27tibICJS2XqSqbKPeTSl2FCIm9ly4D9waEdzMW4GHnL304FzgJdmzL8CWBvcbgBuPYbXFhGZF6JwGc4pxYbC7wM/AHa4+7NmthrYdqQnmFkTcCn58xpw97S7D81Y7CrgLs97CmgJwkdEZEHI5Zx9yVQkdjJDkaHg7ve4+1vd/TPB453u/tGjPG010Ed+/8NzZnaHmTXMWGYF8Pq0x13BtDcwsxvMbIOZbejr6yumZBGRinBgLE06m6uszUdmttLM7jezXjPbb2b3mdnKozwtDqwDbnX384BR4AszX3qW5/nPTXC/3d3Xu/v6jo6OYkoWEakIPcF1FCpt89GdwAPACeS/yT8YTDuSLqDL3Z8OHt9LPiRmLnPitMcrge4iaxIRqXhTV1yrqJ4C0OHud7p7Jrj9HXDEr+zuvg943cxOCya9B3hxxmIPANcGRyFdDCTdvecY6hcRqWiFs5kjsk+hqJPXgH4z+yTw7eDxJ4CBIp73OeBbZpYAdgLXm9mNAO5+G/A94EpgOzBG/sxpEZEFozs5TqIqRlt9otylAMWHwqeAW4C/JL/N/6cU8QHu7puB9TMm3zZtvgOfLbIGEZF5Z19wOGoUTlyD4o8+2uPuH3L3Dndf4u4fJn8im4iIHIeeoVQkRkedcjxXXvvtOatCRGSB6o7IFdemHE8oRKOvIyJSoXI5Z/9wiuURuOLalOMJhZ87n0BERIrXPzrBZNYj1VM44o5mMzvI7B/+BkQn2kREKtDUiWtRuLjOlCOGgrsvKlUhIiILzaErrkWnp3A8m49EROQ4TJ3NrFAQERF6kilq4jHaGqJx4hooFEREyqYnmT9HwSw6B3MqFEREyqRnaDwyo6NOUSiIiJRJlC7DOUWhICJSBtnCiWvqKYiILHj9IxNkcs4y9RRERKR7aOriOuopiIgsePuS0TubGRQKIiJl0R3Bs5lBoSAiUhY9Q+PUVsdoqa8udylvoFAQESmDnuEUy5vrInXiGigURETKomcoWhfXmaJQEBEpg/wQF9HayQwKBRGRkstkc/QenFBPQUREoG9kgmzOI3c2MygURERKburiOlEb9wgUCiIiJTd1Gc6ojZAKCgURkZLbc2AMUE9BRGTBy+aceza8ztkrmmmO2IlroFAQESmpR17cz87+UX71XavLXcqsFAoiIiXi7nz98R2c2FbHB85cVu5yZhVqKJjZLjN7wcw2m9mGWeZfZmbJYP5mM7spzHpERMppw+5BntszxKffuZp4VTS/k8dLsI7L3b3/CPOfcPcPlqAOEZGy+vqPdtBaX83Hzz+x3KUcVjSjSkRkntm2/yA/fKmX697WSV2iqtzlHFbYoeDAw2a20cxuOMwyl5jZ82b2fTM7c7YFzOwGM9tgZhv6+vrCq1ZEJCR/88ROaqtjXHtJZ7lLOaKwNx+93d27zWwJ8IiZvezuj0+bvwlY5e4jZnYl8E/A2pkv4u63A7cDrF+/3kOuWURkTu0fTnH/c3v5xIUn0daQKHc5RxRqT8Hdu4OfvcD9wIUz5g+7+0hw/3tAtZm1h1mTiEip/d1Pd5HNOf/5HdE8DHW60ELBzBrMbNHUfeD9wNYZyyyz4AoTZnZhUM9AWDWJiJRaJpvjng1dvOeMpZy0uL7c5RxVmJuPlgL3B5/5ceBud3/IzG4EcPfbgI8BnzGzDDAOXOPu2jwkIvPGE9v66R+Z4GPnryx3KUUJLRTcfSdwzizTb5t2/xbglrBqEBEpt3s3ddFaX83lpy0pdylF0SGpIiIhSY5N8sjP9nPVuStIxCvj47YyqhQRqUAPbukmnc3x0XWVsekIFAoiIqG5b1MXpy5t5KwVTeUupWgKBRGREOzoG+G5PUN8dN1KggNuKoJCQUQkBP+4qYuYwdXnrSh3KcdEoSAiMsdyOef+TXu59NQOljRF75KbR6JQEBGZY0/uHKA7maqoHcxTFAoiInPsvo1dLKqN8763LC13KcdMoSAiMocOjKb57gs9fOicE6itju4Q2YejUBARmUPfeXYP6Uwu8kNkH45CQURkjmSyOb711B4uWb2Y05YtKnc5b4pCQURkjvzwpV72Do1z3ds6y13Km6ZQEBGZI9/86S5WtNTx3jMqY/C72SgURETmwCv7DvLkzgE+efEq4lWV+9FauZWLiETIN5/cRU08xjUXnFjuUo6LQkFE5Dglxya5f9Nerjr3BFojfg3mo1EoiIgcp3s2vs74ZLaidzBPUSiIiByHdCbHN5/cxQWdrZx5QnO5yzluCgURkeNw509e4/UD4/zaZaeUu5Q5oVAQEXmTepLj3PzoNt57xlIuP71yD0OdTqEgIvIm/eG/vEQ253zpF95S7lLmjEJBRORN+PG2fv5lSw+/fvkpnNhWX+5y5oxCQUTkGKUzOW56YCudi+v59KWry13OnIqXuwARkUpzx493srNvlL+7/oKKHB77SNRTEBE5Blv3Jvnao9v5d2cu5bLT5sfO5ekUCiIiRXr+9SF+8W+eoq0hwe996MxylxMKhYKISBE27h7kk3c8TUt9gn/41YtZ3lxX7pJCoX0KIiJH8cxrB7j+zmdY0lTL3Z++aN4GAoTcUzCzXWb2gpltNrMNs8w3M/uqmW03sy1mti7MekREjtULXUmu+8YzLGuu5Ts3zN8ewpRS9BQud/f+w8y7Algb3C4Cbg1+ioiU3UQmy3+9ZzPNddV8+4aLWbKottwlha7c+xSuAu7yvKeAFjNbXuaaREQA+Nqj23l1/whf+cjZCyIQIPxQcOBhM9toZjfMMn8F8Pq0x13BtDcwsxvMbIOZbejr6wupVBGRQ17oSnLrj3bwsfNXzptxjYoRdii83d3Xkd9M9Fkzu3TGfJvlOf5zE9xvd/f17r6+o6MjjDpFRAomMlk+f8/ztDcm+J8fnD/jGhUj1FBw9+7gZy9wP3DhjEW6gOnXrlsJdIdZk4jI0dzyr9t5Zf9BvvKRs2muqy53OSUVWiiYWYOZLZq6D7wf2DpjsQeAa4OjkC4Gku7eE1ZNIiJHs2nPIH/92A4+um4l7z59abnLKbkwjz5aCtxvZlPrudvdHzKzGwHc/Tbge8CVwHZgDLg+xHpERI7ooa09/NY/PM+yplpuWmCbjaaEFgruvhM4Z5bpt02778Bnw6pBRKQY7s4t/7qdv3jkVc47qYWv/6fzaa5fWJuNpuiMZhFZ0FKTWX7n3i08+Hw3V5+3gq985Ox5N/LpsVAoiMiCNZya5FN3PsvGPYP89w+czo3vWk2wyXvBUiiIyII0NJbm2m88w4vdw/yfX1zHlWfrvFlQKIjIAtQ/MsEn73ianf2j3H7t+QvyKKPDUSiIyIKyL5nil+54ir1D43zjugt4x9r2cpcUKQoFEVkwHtq6jy89sJWRVIa7PnURF57cVu6SIkehICLzXk9ynC/98894+MX9nLG8ib+97gLOWtFc7rIiSaEgIvNW99A4393SzVcf3U4ml+MLV5zOr7zjZKqryj1AdHQpFERk3nB3Nu4e5NGXe/m3l3t5ed9BAN65tp0vf/hsTlpcX+YKo0+hICIVb2Qiwz9u6uKuJ3ezvXeEeMy4oLON/3Hl6Vx+2hJOWdK44M8/KJZCQUQq1v7hFH/9b9u5b9NeRiYynLOymT//+Dm8/8ylNNUuzGEqjpdCQUQqTjbn3P30bv70oVeYyOT44DnLufaSTs49saXcpVU8hcJx+MHP9vGT7f28bc1iLj21g/qEfp0iYXuxe5j/cf8LbH59iHec0s4ffvgsOtsbyl3WvKFPsTdhXzLFTf+8lYdf3E88Ztz15G5q4jHeubadd5++lFOXNrJqcQPtjYlIbcdMZ3LsS6bYOzROzp21SxrpWFQTqRpFputJjvNCV5Kd/aPs7Bvhtf5RNu0ZoqWumr/6j+dy1bkn6O93ji2YUNg9MMrjr/bR1lBDW0OCtoYEHYvy94uVyzl3P7OHP/n+y6SzOX73itO57m2dPLdniIdf3MfDP9vPD1/qLSzfkKhi1eIG1ne28o5T2rl4zeLj2s65L5ni+a4hdg+MsqKlnlOWNNLZXk9NvIrRiQxb9yZ5vmuILV1JBsfSpDM5JjI50pkcB0bT9I1M4DMudtpcV82pSxs5Zcki1nQ0sKajkdUdDaxsracqFs1/tolMlt0DY+zsG6F/JE1VzPI3y/80AzPDgFgwLRE34rEY8ZgxND5J38EJ+g5O0D8yweLGBGevaOGtK5tZ3ly7ID5kcjknnc2RqIoRi9D7fDA1yZM7Bvjx9n5+vL2fnX2jhXntjQlWtzfyqbd38tnLT6Glvvj/XSme+cxPiYhbv369b9iw4Zif98+b9/JfvrP556avO6mFX7xoFf/+7OXUJd44XG4u57yy/yDP7jrAs7sGefa1A+wbTvH2UxbzR1efzarFb+yyuju7B8Z4bWCU3f2j7BoYY0ffCBt2DTI+maUqZpyzspl3ru3gstM6eOvKlsIHr7uzo2+Up3YOsHtglMmsM5nNMZnNf6Bv6UrSe3Di5+qPGSxrqmXfcIpc8FaubK1jaVMtiaoYNdUxElUxWuqrWdFSz/KWWla01AGwbf9BXu0dYdv+g2zrHWFobLLwujXxGBetXsy7Tu3gXad2sKaj4U19WB5MTbJ7YIzdA2MMjE7QWBOnua6a5rpqFtVW4ziZrJPNOZlcjv6RNPuHU8FtgtGJTCHYJjJZ9g9P0DU4Vmjr8YgZtDXUMDiWJhu8YHtjgjOWN7Gmo5E1SxpZ09FAQyLOjr4RtveOsK13hJ7keCGA4lUxauIxljXVsqK1jpWt9axsreOM5U0lu4xjajLLgdE0AyNp+kZSQdjlHw+NpRkan2RoLE1yfJKRiQyjE1lG05nCF4SaeIy6RBV11VW01CdYHHxpamtI0Lm4nlOXLmLt0kWh9Xwnszl+9Eof9z+3l0de2k86k6OuuoqLVrfxjlPaWbeqlTUdjQvusphzzcw2uvv6oy63UEIhk81xYCzNgdFDt90DY9y3qYudfaMsqo3z4XNX0FAT57X+EXb1j7FrYJSJTA7If/BecHIb73vLUn7hrcuP6Z8jncmxac8gP9nez+Pb+tnSNYQ7tDUkeOfadnIOT+0coC/40K+J5z9oEvEY1VUxGmvinLWimbeuzN9Wtzeyd2icHX0j7OgdYc+BMU5a3MC5Jzbz1pUttDfWHPPvB+DAaJqdfSPs7BvlxZ5hntjWx47gm9oJzbUsaarN11ZdRW3wcyp4auIx0pkcQ2OTDI2nGRydpPdgiv6R9JuqpSpmdDTWsKg2Hrx+fl1tjYn8B3ZHA6vbG1naVEPOIZPLkc3lw8XJh6w7hXmZIGQzOae5rpqORTW01ieoihmpySwv9gzzQle+p7Vt/wg7+kYYS2ffUFM8ZnS2N3Biax0OZLL5IEtN5uhJjtN78FBPzAxOX9bEBZ2trO9s45SORpY01dBWnyh8M0+OTfLawCiv9Y/QOzxBJufkck42qD0Rzwd6Ip7/Nj84mqb3YIre4Qn6RiYYGMn/HY9MZGb9HTYk8h/yrQ3VtNQlaK6rprEmTkNNnMaaKmqqq0hncqQms4xPZhmdyJIcTzMQ/H8MjLzxtdsaEqxoqaO1IUFbfXXwM0FbY/CzIcGi2mriVUbMjKkOyHAqUwil4fFJRtNZxiYyjKazDI6leeyVPg6MpmlrSPChc07gA2ctY91JrSTiOsFsLikUiuTuPPPaAb79zB6+t3Uf7s5JbfWc3N5A5+IGzljexIUnt7GytW7OviUNjqZ5fFsfP3qlj8e39VEVMy5evbhw61xcH5lNGK8fGOPxbX08tfMAyfFJUpNZJjI5Jiazhc1TE5ksE5M5EvF8j6SlPkFrfTXtjTWsWtxA5+J6Vi1uoGNRDSMTGZLjk/lvrakMMSP4xm1UxWIsbkiwtKmWtoZEWTdfuTv7hlPs6B1lZCLDKUsaWLW44Yhnwk5ksvQMpdh9YIzn9gyyYdcgm/YMviFc4jGjvbGGyWyOgdFjD8zW+nygdSyqob0xv/kz/81+alqiMO94LxTj7vQdnODV/SO8uv8gr+4/yP7hFAfGJhkcPXIgHY0Z1FdXUV8T58KT2/jIeSu49NQOnWkcIoXCm5CazFJdFYvstnSpPJlsjpf3HWTPgTF6h1P0Hpyg9+AE1VXG6vZGTm5v4OSOBpY11eaDMdgsBZDO5jebpTP5XlBLfSJy354nMlkGRycLve+DqUmy7uQ8v/kVoKkuTnPQU2mqi7Ooppra6lhkvvgsFMWGwoLZ0VyMhXwJPglHvCrGWSua39TgazXxKmri0f6brIlXsay5imXNteUuReZItL52iIhIWSkURESkQKEgIiIFCgURESlQKIiISIFCQUREChQKIiJSoFAQEZGCijuj2cz6gN0zJjcDyaNMO9LjqfvTp7UD/cdR6mw1FbvMXLVn+v2ot2fmtEprz2zTK6U9h5un9syv9qxy946jVpofOKyyb8DtR5t2pMdT92dM2zDXNRW7zFy1Z0bbIt2eYtoQ5fa8mfckKu0p9j1Seyq/PcXc5svmoweLmHakxw8eZpnjUcxrHW6ZuWpPsXUUI+z2zJxWae2ZbXqltOdw89Se+deeo6q4zUelYmYbvIjBoyqF2hNtak+0zbf2HMl86SmE4fZyFzDH1J5oU3uibb6157DUUxARkQL1FEREpGBBhIKZfcPMes1s65t47vlm9oKZbTezr9q0K4OY2efM7BUz+5mZ/encVn3Emua8PWb2e2a218w2B7cr577yw9YUyvsTzP+8mbmZtc9dxUetKYz35w/MbEvw3jxsZifMfeWHrSmM9vyZmb0ctOl+M2uZ+8oPW1MY7fl48DmQM7PK3vdwPIdZVcoNuBRYB2x9E899BrgEMOD7wBXB9MuBHwI1weMlFd6e3wM+P1/en2DeicAPyJ/X0l7J7QGapi3zG8BtFd6e9wPx4P6fAH9S4e05AzgNeAxYX6q2hHFbED0Fd38cODB9mpmtMbOHzGyjmT1hZqfPfJ6ZLSf/z/ik59/5u4APB7M/A/yxu08E6+gNtxWHhNSesgmxPX8J/DegpDvOwmiPuw9PW7SBErYppPY87O5TF3h+ClgZbisOCak9L7n7K6WoP2wLIhQO43bgc+5+PvB54K9nWWYF0DXtcVcwDeBU4J1m9rSZ/cjMLgi12qM73vYA/HrQnf+GmbWGV2pRjqs9ZvYhYK+7Px92oUU67vfHzL5sZq8DvwTcFGKtxZiLv7cpnyL/rbuc5rI9FW1BXqPZzBqBtwH3TNsEXTPborNMm/qGFgdagYuBC4D/Z2arg28QJTVH7bkV+IPg8R8Af0H+n7Xkjrc9ZlYPfJH8Joqym6P3B3f/IvBFM/td4NeBL81xqUWZq/YEr/VFIAN8ay5rPBZz2Z75YEGGAvke0pC7nzt9oplVARuDhw+Q/6Cc3q1dCXQH97uAfwxC4Bkzy5EfH6UvzMIP47jb4+77pz3vb4DvhlnwURxve9YAJwPPB//kK4FNZnahu+8LufbZzMXf23R3A/9CmUKBOWqPmV0HfBB4Tzm+TE0z1+9PZSv3To1S3YBOpu1YAn4KfDy4b8A5h3nes+R7A1M7lq4Mpt8I/H5w/1TgdYLzPiq0PcunLfNbwHcq+f2ZscwuSrijOaT3Z+20ZT4H3Fvh7fkA8CLQUcp2hP33xjzY0Vz2Akr0B/BtoAeYJP8N/1fIf5N8CHg++OO86TDPXQ9sBXYAt0x98AMJ4O+DeZuAd1d4e/4v8AKwhfy3ouWV3J4Zy5Q0FEJ6f+4Lpm8hP5bNigpvz3byX6Q2B7dSHk0VRnuuDl5rAtgP/KBU7Znrm85oFhGRgoV89JGIiMygUBARkQKFgoiIFCgURESkQKEgIiIFCgWZF8xspMTru8PM3jJHr5UNRj/damYPHm3EUDNrMbNfm4t1i8ykQ1JlXjCzEXdvnMPXi/uhAdtCNb12M/sm8Kq7f/kIy3cC33X3s0pRnyws6inIvGVmHWZ2n5k9G9zeHky/0Mx+ambPBT9PC6b/spndY2YPAg+b2WVm9piZ3RuM/f+taePnPzY1br6ZjQSD1T1vZk+Z2dJg+prg8bNm9vtF9mae5NCgfo1m9qiZbbL8GP5XBcv8MbAm6F38WbDs7wTr2WJm/2sOf42ywCgUZD67GfhLd78A+ChwRzD9ZeBSdz+P/GijfzSj4M6pAAACIElEQVTtOZcA17n7u4PH5wG/CbwFWA28fZb1NABPufs5wOPAp6et/+Zg/UcdIycYa+c95M8oB0gBV7v7OvLX7/iLIJS+AOxw93Pd/XfM7P3AWuBC4FzgfDO79GjrE5nNQh0QTxaG9wJvmTbyZZOZLQKagW+a2Vryo1xWT3vOI+4+faz9Z9y9C8DMNpMfM+fHM9aT5tAAghuB9wX3L+HQ9R3uBv78MHXWTXvtjcAjwXQD/ij4gM+R70EsneX57w9uzwWPG8mHxOOHWZ/IYSkUZD6LAZe4+/j0iWb2NeDf3P3qYPv8Y9Nmj854jYlp97PM/j8z6Yd2zh1umSMZd/dzzayZfLh8Fvgq+esmdADnu/ukme0Camd5vgFfcfevH+N6RX6ONh/JfPYw+esOAGBmU0MjNwN7g/u/HOL6nyK/2QrgmqMt7O5J8pfa/LyZVZOvszcIhMuBVcGiB4FF0576A+BTwXUBMLMVZrZkjtogC4xCQeaLejPrmnb7bfIfsOuDna8vkh/uHOBPga+Y2U+AqhBr+k3gt83sGWA5kDzaE9z9OfIjdV5D/sIz681sA/lew8vBMgPAT4JDWP/M3R8mv3nqSTN7AbiXN4aGSNF0SKpISIIrwI27u5vZNcAn3P2qoz1PpJy0T0EkPOcDtwRHDA1RpsubihwL9RRERKRA+xRERKRAoSAiIgUKBRERKVAoiIhIgUJBREQKFAoiIlLw/wEZzwH5EKQR9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(); learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='4', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [2/4 15:40<15:40]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>4.075088</th>\n",
       "    <th>3.874008</th>\n",
       "    <th>0.118218</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>3.618849</th>\n",
       "    <th>3.475125</th>\n",
       "    <th>0.202030</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='544' class='' max='10100', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      5.39% [544/10100 00:22<06:26 3.6088]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(4, max_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4, max_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4, max_lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = fastai.basic_train.Learner(data, model=core.cnn(nc=data.c), loss_func=nn.CrossEntropyLoss(), metrics=fastai.metrics.accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(12, max_lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up \n",
    "Feel free to check out /.core for implementation details..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = {'train':data.train_dl, 'val':data.valid_dl}\n",
    "model = core.cnn(nc=data.c).cuda()\n",
    "model.init_opts()\n",
    "model.init_params()\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), betas=(0.65,0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_splice = [[64,1,0], [64,1,0], [128,2,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nf, b_idx, i_idx in initial_splice:\n",
    "    model.splice(nf=nf, b_idx=b_idx, i_idx=i_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrf = core.LearningRateFinder(opt, nits=300, min_lr=1e-6, max_lr=1e-1)\n",
    "lrf.lr_find(model, data.train_dl, crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(crit, dls, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "class Smoother():\n",
    "    def __init__(self, beta=0.95):\n",
    "        self.beta, self.n, self.mov_avg = beta, 0, 0\n",
    "        self.vals = []\n",
    "\n",
    "    def add_value(self, val):\n",
    "        self.n += 1\n",
    "        self.mov_avg = self.beta * self.mov_avg + (1-self.beta)*val\n",
    "        self.vals.append(self.mov_avg/(1-self.beta**self.n))\n",
    "\n",
    "    def process(self,array):\n",
    "        for item in array:\n",
    "            self.add_value(item)\n",
    "        return self.vals\n",
    "\n",
    "    def reset(self):\n",
    "        self.n, self.mov_avg, self.vals = 0,0,[]\n",
    "\n",
    "class Stepper():\n",
    "    def __init__(self, opt):\n",
    "        self.it = 0\n",
    "        self.opt = opt\n",
    "        self.nits = 1\n",
    "\n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.opt.zero_grad()\n",
    "    \n",
    "    @staticmethod\n",
    "    def cosine_anneal(pct, max_val, min_val):\n",
    "        return min_val + (max_val - min_val) / 2 *(1+np.cos(np.pi * pct))\n",
    "    \n",
    "    @staticmethod\n",
    "    def exp_anneal(pct, start, stop):\n",
    "        return start * (stop/start)**pct\n",
    "    \n",
    "    @staticmethod\n",
    "    def linear_anneal(pct, start, stop):\n",
    "        return (1-pct)*start + pct*stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateFinder(Stepper):\n",
    "    def __init__(self, opt, nits=500, min_lr=1e-6, max_lr=1e-1):\n",
    "        super(LearningRateFinder, self).__init__(opt)\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.pct_start = 0\n",
    "        self.nits = nits\n",
    "        for group in self.opt.param_groups:\n",
    "            group['lr'] = min_lr\n",
    "    \n",
    "    def step(self):\n",
    "        self.opt.step()\n",
    "        self.it+=1 \n",
    "        new_lr = self.exp_anneal(self.it / self.nits, self.min_lr, self.max_lr)\n",
    "        for group in self.opt.param_groups:\n",
    "            group['lr'] = new_lr\n",
    "    \n",
    "    def plot_lr_find(self,tr_history, clip=True):                                \n",
    "        fig, ax = plt.subplots()\n",
    "        if clip:\n",
    "            start = int(0.05 * len(tr_history))\n",
    "            end = int(0.90 * len(tr_history))\n",
    "            tr_history = tr_history.iloc[start:end]\n",
    "        ax.plot(tr_history.learning_rate, tr_history.tr_loss)\n",
    "        ax.set_xscale('log')\n",
    "        ax.legend()\n",
    "        ax.set_xlabel('Learning Rate')\n",
    "        ax.set_ylabel('Loss')\n",
    "        rec_idx = self.suggest_lr(tr_history)\n",
    "        rec_lr, rec_loss = tr_history.iloc[rec_idx].learning_rate, tr_history.iloc[rec_idx].tr_loss\n",
    "        ax.plot([rec_lr],[rec_loss], 'x', color='k')\n",
    "        plt.title('Suggested Learning Rate: {:.2E}'.format(rec_lr))\n",
    "        return rec_lr\n",
    "\n",
    "    def suggest_lr(self, tr_history, n_samples=200):\n",
    "        tr_history = tr_history.reset_index(drop=True)\n",
    "        \n",
    "        pct_25 = int(0.25 * len(tr_history))\n",
    "        pct_75 = int(0.75 * len(tr_history))\n",
    "        \n",
    "        start_samples = sorted(np.random.choice(tr_history.index[:pct_25], n_samples // 4, replace=False))\n",
    "        middle_samples = sorted(np.random.choice(tr_history.index[pct_25:pct_75], n_samples // 2, replace=False))\n",
    "        end_samples = sorted(np.random.choice(tr_history.index[pct_75:], n_samples // 4, replace=False))\n",
    "        \n",
    "        sample_idxs = np.array(start_samples + middle_samples + end_samples)\n",
    "        xs = [x / len(tr_history) for x in sample_idxs]\n",
    "        ys = tr_history.iloc[sample_idxs].tr_loss.values\n",
    "        \n",
    "        tck = sp.interpolate.splrep(xs, ys, t=[], k=3)\n",
    "        line = sp.interpolate.splev(xs, tck, der=2)\n",
    "        rec_pct = -line[0]/(line[-1] - line[0])\n",
    "        rec_idx = int(rec_pct * len(tr_history))\n",
    "        \n",
    "        return rec_idx\n",
    "    \n",
    "    def lr_find(self, model, tr_dl, criterion, **kwargs):\n",
    "        tr_losses = []\n",
    "        lrs = []\n",
    "        self.it = 0 \n",
    "        old_params = model.state_dict()\n",
    "        while self.it <= self.nits:\n",
    "            for inputs, labels in tr_dl:\n",
    "                if self.it > self.nits:\n",
    "                    break\n",
    "                self.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                self.step()\n",
    "                tr_losses.append(loss.item())\n",
    "                lrs.append(self.opt.param_groups[-1]['lr'])\n",
    "        tr_losses = Smoother(beta=0.99).process(tr_losses)\n",
    "        tr_history = pd.DataFrame({'tr_loss':tr_losses, 'learning_rate':lrs})\n",
    "        rec_lr = self.plot_lr_find(tr_history)\n",
    "        model.load_state_dict(old_params)\n",
    "        return rec_lr, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd; import numpy as np;  import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'test':np.arange(5000)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(np.random.choice(df.index[:int(0.25*len(df))], 5, replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = fastai.datasets.URLs.MNIST\n",
    "path = fastai.datasets.untar_data(url, force_download=True)\n",
    "data = fastai.vision.ImageDataBunch.from_folder(path, train='training', valid='testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples // 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
